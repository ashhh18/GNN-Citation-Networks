{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from multiprocessing import cpu_count\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch_geometric.transforms as T\n",
    "from gensim.models import Word2Vec\n",
    "Gr = nx.DiGraph()\n",
    "Gr1 = nx.DiGraph()\n",
    "with open('Datasets/1992to1994.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('Datasets/1994to1998.txt','r') as f:\n",
    "    lines1 = f.readlines()\n",
    "edges = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    if count < 4:\n",
    "        count += 1\n",
    "    else:\n",
    "        linesp = line.strip().split()\n",
    "        edges.append((int(linesp[0]), int(linesp[1])))\n",
    "        count+=1\n",
    "\n",
    "Gr.add_edges_from(edges)\n",
    "edges = []\n",
    "count = 0\n",
    "\n",
    "for line in lines1:\n",
    "    if count < 4:\n",
    "        count += 1\n",
    "    else:\n",
    "        linesp = line.strip().split()\n",
    "        edges.append((int(linesp[0]), int(linesp[1])))\n",
    "        count+=1\n",
    "\n",
    "Gr1.add_edges_from(edges)\n",
    "for edge in Gr.edges():\n",
    "\tGr[edge[0]][edge[1]][1] = 1\n",
    "for edge in Gr1.edges():\n",
    "\tGr1[edge[0]][edge[1]][1] = 1\n",
    "# now we have our graph Gr\n",
    "p=1\n",
    "q=1\n",
    "dimensions=7\n",
    "num_walks=10\n",
    "walk_length=80\n",
    "window_size=10\n",
    "iter=1\n",
    "workers=cpu_count()\n",
    "import numpy as np\n",
    "import random\n",
    "class Graph():\n",
    "\tdef __init__(self, nx_G, is_directed, p, q):\n",
    "\t\tself.G = nx_G\n",
    "\t\tself.is_directed = is_directed\n",
    "\t\tself.p = p\n",
    "\t\tself.q = q\n",
    "\n",
    "\tdef node2vec_walk(self, walk_length, start_node):\n",
    "\t\tG = self.G\n",
    "\t\talias_nodes = self.alias_nodes\n",
    "\t\talias_edges = self.alias_edges\n",
    "\n",
    "\t\twalk = [start_node]\n",
    "\n",
    "\t\twhile len(walk) < walk_length:\n",
    "\t\t\tcur = walk[-1]\n",
    "\t\t\tcur_nbrs = sorted(G.neighbors(cur))\n",
    "\t\t\tif len(cur_nbrs) > 0:\n",
    "\t\t\t\tif len(walk) == 1:\n",
    "\t\t\t\t\twalk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprev = walk[-2]\n",
    "\t\t\t\t\tnext = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], \n",
    "\t\t\t\t\t\talias_edges[(prev, cur)][1])]\n",
    "\t\t\t\t\twalk.append(next)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn walk\n",
    "\n",
    "\tdef simulate_walks(self, num_walks, walk_length):\n",
    "\t\tG = self.G\n",
    "\t\twalks = []\n",
    "\t\tnodes = list(G.nodes())\n",
    "\t\tprint('Walk iteration:')\n",
    "\t\tfor walk_iter in range(num_walks):\n",
    "\t\t\tprint(str(walk_iter+1), '/', str(num_walks))\n",
    "\t\t\trandom.shuffle(nodes)\n",
    "\t\t\tfor node in nodes:\n",
    "\t\t\t\twalks.append(self.node2vec_walk(walk_length=walk_length, start_node=node))\n",
    "\n",
    "\t\treturn walks\n",
    "\n",
    "\tdef get_alias_edge(self, src, dst):\n",
    "\t\tG = self.G\n",
    "\t\tp = self.p\n",
    "\t\tq = self.q\n",
    "\n",
    "\t\tunnormalized_probs = []\n",
    "\t\tfor dst_nbr in sorted(G.neighbors(dst)):\n",
    "\t\t\tif dst_nbr == src:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr][1]/p)\n",
    "\t\t\telif G.has_edge(dst_nbr, src):\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr][1])\n",
    "\t\t\telse:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr][1]/q)\n",
    "\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\n",
    "\t\treturn alias_setup(normalized_probs)\n",
    "\n",
    "\tdef preprocess_transition_probs(self):\n",
    "\t\tG = self.G\n",
    "\t\tis_directed = self.is_directed\n",
    "\n",
    "\t\talias_nodes = {}\n",
    "\t\tfor node in G.nodes():\n",
    "\t\t\tunnormalized_probs = [G[node][nbr][1] for nbr in sorted(G.neighbors(node))]\n",
    "\t\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\t\t\talias_nodes[node] = alias_setup(normalized_probs)\n",
    "\n",
    "\t\talias_edges = {}\n",
    "\t\ttriads = {}\n",
    "\n",
    "\t\tif is_directed:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\telse:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\t\t\talias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])\n",
    "\n",
    "\t\tself.alias_nodes = alias_nodes\n",
    "\t\tself.alias_edges = alias_edges\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "def alias_setup(probs):\n",
    "        K = len(probs)\n",
    "        q = np.zeros(K)\n",
    "        J = np.zeros(K, dtype=float)\n",
    "\n",
    "        smaller = []\n",
    "        larger = []\n",
    "        for kk, prob in enumerate(probs):\n",
    "            q[kk] = K*prob\n",
    "            if q[kk] < 1.0:\n",
    "                smaller.append(kk)\n",
    "            else:\n",
    "                larger.append(kk)\n",
    "\n",
    "        while len(smaller) > 0 and len(larger) > 0:\n",
    "            small = smaller.pop()\n",
    "            large = larger.pop()\n",
    "\n",
    "            J[small] = large\n",
    "            q[large] = q[large] + q[small] - 1.0\n",
    "            if q[large] < 1.0:\n",
    "                smaller.append(large)\n",
    "            else:\n",
    "                larger.append(large)\n",
    "\n",
    "        return J, q\n",
    "\n",
    "def alias_draw(J, q):\n",
    "        K = len(J)\n",
    "\n",
    "        kk = int(np.floor(np.random.rand()*K))\n",
    "        if np.random.rand() < q[kk]:\n",
    "            return kk\n",
    "        else:\n",
    "            return J[kk]\n",
    "        \n",
    "G=Graph(Gr, True, p, q)\n",
    "G.preprocess_transition_probs()\n",
    "walks = G.simulate_walks(num_walks, walk_length)\n",
    "walks = [list(map(str, walk)) for walk in walks]\n",
    "model = Word2Vec(walks, vector_size=dimensions, window=window_size, min_count=0, sg=1, workers=workers, epochs=iter)\n",
    "emb_mappings = model.wv\n",
    "G1=Graph(Gr1, True, p, q)\n",
    "G1.preprocess_transition_probs()\n",
    "walks1 = G1.simulate_walks(num_walks, walk_length)\n",
    "walks1 = [list(map(str, walk)) for walk in walks1]\n",
    "model1 = Word2Vec(walks1, vector_size=dimensions, window=window_size, min_count=0, sg=1, workers=workers, epochs=iter)\n",
    "emb_mappings1 = model1.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pyg_utils.convert.from_networkx(Gr)\n",
    "transform=T.RandomLinkSplit(add_negative_train_samples=True)\n",
    "data_train,data_val,data_test = transform(data)\n",
    "data1=pyg_utils.convert.from_networkx(Gr1)\n",
    "positive_edge_train = []\n",
    "negative_edge_train = []\n",
    "positive_edge_val = []\n",
    "negative_edge_val = []\n",
    "positive_edge_test = []\n",
    "negative_edge_test = []\n",
    "for i in range(0,len(data_train.edge_label)):\n",
    "    if(data_train.edge_label[i]==1):\n",
    "        positive_edge_train.append(data_train.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_train.append(data_train.edge_label_index[:,i].tolist())\n",
    "for i in range(0,len(data_val.edge_label)):\n",
    "    if(data_val.edge_label[i]==1):\n",
    "        positive_edge_val.append(data_val.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_val.append(data_val.edge_label_index[:,i].tolist())\n",
    "for i in range(0,len(data_test.edge_label)):\n",
    "    if(data_test.edge_label[i]==1):\n",
    "        positive_edge_test.append(data_test.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_test.append(data_test.edge_label_index[:,i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link prediction using GNN node embeddings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 140382], 1=[140382], num_nodes=17362)\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for node_index in range(0, data.num_nodes):\n",
    "    # node_str = str(node_index)\n",
    "    node_emb = emb_mappings[node_index]\n",
    "    emb_list.append(node_emb)\n",
    "emb_matrix = np.vstack(emb_list)\n",
    "print(data1)\n",
    "emb_list1 = []\n",
    "for node_index in range(0, data1.num_nodes):\n",
    "    # node_str = str(node_index)\n",
    "    node_emb = emb_mappings1[node_index]\n",
    "    emb_list1.append(node_emb)\n",
    "emb_matrix1 = np.vstack(emb_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_embeddings(edge_list,choice):\n",
    "    embs = []\n",
    "    if(choice==0):\n",
    "        for edge in edge_list:\n",
    "            node1 = edge[0]\n",
    "            node2 = edge[1]\n",
    "            emb1 = emb_matrix[node1]\n",
    "            emb2 = emb_matrix[node2]\n",
    "            edge_emb = np.multiply(emb1, emb2)\n",
    "            embs.append(edge_emb)\n",
    "    else:\n",
    "        for edge in edge_list:\n",
    "            node1 = edge[0]\n",
    "            node2 = edge[1]\n",
    "            emb1 = emb_matrix1[node1]\n",
    "            emb2 = emb_matrix1[node2]\n",
    "            edge_emb = np.multiply(emb1, emb2)\n",
    "            embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train_edge_embs = get_edge_embeddings(positive_edge_train,0)\n",
    "neg_train_edge_embs = get_edge_embeddings(negative_edge_train,0)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(positive_edge_train)), np.zeros(len(negative_edge_train))])\n",
    "\n",
    "# Val-set edge embeddings, labels\n",
    "pos_val_edge_embs = get_edge_embeddings(positive_edge_val,0)\n",
    "neg_val_edge_embs = get_edge_embeddings(negative_edge_val,0)\n",
    "val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
    "val_edge_labels = np.concatenate([np.ones(len(positive_edge_val)), np.zeros(len(negative_edge_val))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(positive_edge_test,0)\n",
    "neg_test_edge_embs = get_edge_embeddings(negative_edge_test,0)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(positive_edge_test)), np.zeros(len(negative_edge_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec Validation ROC score:  0.6531917107699512\n",
      "node2vec Validation AP score:  0.6648211930307945\n",
      "node2vec Test ROC score:  0.6524833261736136\n",
      "node2vec Test AP score:  0.6637982342578719\n"
     ]
    }
   ],
   "source": [
    "edge_classifier = LogisticRegression(random_state=0)\n",
    "edge_classifier.fit(train_edge_embs, train_edge_labels)\n",
    "\n",
    "\n",
    "data=pyg_utils.convert.from_networkx(Gr1)\n",
    "transform=T.RandomLinkSplit(add_negative_train_samples=True)\n",
    "data_train,data_val,data_test = transform(data)\n",
    "\n",
    "positive_edge_train = []\n",
    "negative_edge_train = []\n",
    "positive_edge_val = []\n",
    "negative_edge_val = []\n",
    "positive_edge_test = []\n",
    "negative_edge_test = []\n",
    "for i in range(0,len(data_train.edge_label)):\n",
    "    if(data_train.edge_label[i]==1):\n",
    "        positive_edge_train.append(data_train.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_train.append(data_train.edge_label_index[:,i].tolist())\n",
    "for i in range(0,len(data_val.edge_label)):\n",
    "    if(data_val.edge_label[i]==1):\n",
    "        positive_edge_val.append(data_val.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_val.append(data_val.edge_label_index[:,i].tolist())\n",
    "for i in range(0,len(data_test.edge_label)):\n",
    "    if(data_test.edge_label[i]==1):\n",
    "        positive_edge_test.append(data_test.edge_label_index[:,i].tolist())\n",
    "    else:\n",
    "        negative_edge_test.append(data_test.edge_label_index[:,i].tolist())\n",
    "        \n",
    "\n",
    "pos_val_edge_embs = get_edge_embeddings(positive_edge_val,1)\n",
    "neg_val_edge_embs = get_edge_embeddings(negative_edge_val,1)\n",
    "val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
    "val_edge_labels = np.concatenate([np.ones(len(positive_edge_val)), np.zeros(len(negative_edge_val))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(positive_edge_test,1)\n",
    "neg_test_edge_embs = get_edge_embeddings(negative_edge_test,1)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(positive_edge_test)), np.zeros(len(negative_edge_test))])\n",
    "\n",
    "\n",
    "val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
    "val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
    "val_ap = average_precision_score(val_edge_labels, val_preds)\n",
    "\n",
    "test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds)\n",
    "\n",
    "print ('node2vec Validation ROC score: ', str(val_roc))\n",
    "print ('node2vec Validation AP score: ', str(val_ap))\n",
    "print ('node2vec Test ROC score: ', str(test_roc))\n",
    "print ('node2vec Test AP score: ', str(test_ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
